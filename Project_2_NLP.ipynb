{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_2_NLP.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urness/CS167Project2/blob/main/Project_2_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu0Kz0Nq4ui4"
      },
      "source": [
        "# Project \\#2 Starter Code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBZAVjcWhgBV"
      },
      "source": [
        "# Input Pipeline (sklearn):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12XGv2fIfTSr"
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas\n",
        "drive.mount('/content/drive')\n",
        "data = pandas.read_csv('/content/drive/MyDrive/CS167Spring22/datasets/IMDB_dataset.csv')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICUC-PvQ5bP2"
      },
      "source": [
        "## Data Exploration:\n",
        "- Number of samples\n",
        "- Number of classes of the target variable\n",
        "- Number of words per sample\n",
        "- Distribution of sample length\n",
        "- Something else: get creative :) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kkCmgdf5ZqB"
      },
      "source": [
        "## Use cells here to explore the data:\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSuguZ6u5lUl"
      },
      "source": [
        "## Data Preparation\n",
        "\n",
        "I'm providing you with code that cleans the reviews by making it all lowercase letters and removing stop words. The three cells below do this for you. I still want you to explain what you did with the data here. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV4FfvLegTSh"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import nltk\n",
        "#only do next line once\n",
        "nltk.download() #in Corpora tab, download stopwords\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "#The NLTK downloader will open, you need to select (d) for Download, and then 'stopwords'then (q) to quit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTEr6vRUgOUs"
      },
      "source": [
        "#This is a function that takes in a review, makes sure it is only lower case letters and removes stopwords.\n",
        "#It returns the cleaned review text.\n",
        "def clean_review(review):\n",
        "    #input is a string review\n",
        "    #return is review cleaned of all punctuation, lowercase, and removed nltk stopwords\n",
        "    letters_only = re.sub(\"[^a-zA-Z]\",\" \",review)\n",
        "    lower_case = letters_only.lower()\n",
        "    words = lower_case.split()\n",
        "    for stop_word in stopwords.words(\"english\"):\n",
        "        while stop_word in words:\n",
        "            words.remove(stop_word)\n",
        "    cleaned = \" \".join(words)\n",
        "    return cleaned"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEjHsILZgk9V"
      },
      "source": [
        "#process the data\n",
        "cleaned_text = []\n",
        "for i in range(len(data)):\n",
        "    cleaned_text.append(clean_review(data[\"review\"][i]))  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMg3P0ZNBvGM"
      },
      "source": [
        "cleaned_text[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spDgSTvCg9wk"
      },
      "source": [
        "#establish training and testing dataset\n",
        "train_data, test_data, train_sln, test_sln = \\\n",
        "    train_test_split(cleaned_text, data['sentiment'], test_size = 0.2, random_state=0) "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-86AHOAkDpge"
      },
      "source": [
        "### Vectorizing the data\n",
        "\n",
        "**CountVectorizer**: Convert a collection of text documents to a matrix of token counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwmex98NDgqJ"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "\n",
        "#Bag of Words with 5000 most common words\n",
        "vectorizer = CountVectorizer(analyzer='word', max_features = 5000)\n",
        "#find the right 5000 words\n",
        "vectorizer.fit(train_data)\n",
        "\n",
        "#use the vectorizer to transform review strings into word count vectors \n",
        "train_data_vectors = vectorizer.transform(train_data).toarray()\n",
        "test_data_vectors = vectorizer.transform(test_data).toarray()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUSQcsLOEAec"
      },
      "source": [
        "## Now use train_data_vectors and test_data_vectors to train/test/tune your sklearn models.\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}